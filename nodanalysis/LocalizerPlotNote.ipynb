{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some standard/utility libraries:\n",
    "import os, sys, six # six provides python 2/3 compatibility\n",
    "\n",
    "# Import our numerical/scientific libraries, scipy and numpy:\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nibabel as nib\n",
    "from os.path import join as pjoin\n",
    "import h5py\n",
    "from nod_utils import save_ciftifile\n",
    "# The neuropythy library is a swiss-army-knife for handling MRI data, especially\n",
    "# anatomical/structural data such as that produced by FreeSurfer or the HCP.\n",
    "# https://github.com/noahbenson/neuropythy\n",
    "import neuropythy as ny\n",
    "\n",
    "# Import graphics libraries:\n",
    "# Matplotlib/Pyplot is our 2D graphing library:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We also import ipyvolume, the 3D graphics library used by neurropythy, for 3D\n",
    "# surface rendering (optional).\n",
    "import ipyvolume as ipv\n",
    "\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from nibabel.cifti2 import cifti2\n",
    "from collections import OrderedDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiftiReader(object):\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.full_data = cifti2.load(file_path)\n",
    "\n",
    "    @property\n",
    "    def header(self):\n",
    "        return self.full_data.header\n",
    "\n",
    "    @property\n",
    "    def brain_structures(self):\n",
    "        return [_.brain_structure for _ in self.header.get_index_map(1).brain_models]\n",
    "\n",
    "    @property\n",
    "    def label_info(self):\n",
    "        \"\"\"\n",
    "        Get label information from label tables\n",
    "        Return:\n",
    "        ------\n",
    "        label_info[list]:\n",
    "            Each element is a dict about corresponding map's label information.\n",
    "            Each dict's content is shown as below:\n",
    "                key[list]: a list of integers which are data values of the map\n",
    "                label[list]: a list of label names\n",
    "                rgba[ndarray]: shape=(n_label, 4)\n",
    "                    The four elements in the second dimension are\n",
    "                    red, green, blue, and alpha color components for label (between 0 and 1).\n",
    "        \"\"\"\n",
    "        label_info = []\n",
    "        for named_map in self.header.get_index_map(0).named_maps:\n",
    "            label_dict = {'key': [], 'label': [], 'rgba': []}\n",
    "            for k, v in named_map.label_table.items():\n",
    "                label_dict['key'].append(k)\n",
    "                label_dict['label'].append(v.label)\n",
    "                label_dict['rgba'].append(v.rgba)\n",
    "            label_dict['rgba'] = np.asarray(label_dict['rgba'])\n",
    "            label_info.append(label_dict)\n",
    "\n",
    "        return label_info\n",
    "\n",
    "    @property\n",
    "    def volume(self):\n",
    "        return self.header.get_index_map(1).volume\n",
    "\n",
    "    def brain_models(self, structures=None):\n",
    "        \"\"\"\n",
    "        get brain model from cifti file\n",
    "        Parameter:\n",
    "        ---------\n",
    "        structures: list of str\n",
    "            Each structure corresponds to a brain model.\n",
    "            If None, get all brain models.\n",
    "        Return:\n",
    "        ------\n",
    "            brain_models: list of Cifti2BrainModel\n",
    "        \"\"\"\n",
    "        brain_models = list(self.header.get_index_map(1).brain_models)\n",
    "        if structures is not None:\n",
    "            if not isinstance(structures, list):\n",
    "                raise TypeError(\"The parameter 'structures' must be a list\")\n",
    "            b_strus = [bm.brain_structure for bm in brain_models]\n",
    "            brain_models = [brain_models[b_strus.index(s)] for s in structures]\n",
    "        return brain_models\n",
    "\n",
    "    def map_names(self, map_indices=None):\n",
    "        \"\"\"\n",
    "        get map names\n",
    "        Parameters:\n",
    "        ----------\n",
    "        map_indices: sequence of integer\n",
    "            Specify which map names should be got.\n",
    "            If None, get all map names\n",
    "        Return:\n",
    "        ------\n",
    "        map_names: list of str\n",
    "        \"\"\"\n",
    "        named_maps = list(self.header.get_index_map(0).named_maps)\n",
    "        if named_maps:\n",
    "            if map_indices is None:\n",
    "                map_names = [nm.map_name for nm in named_maps]\n",
    "            else:\n",
    "                map_names = [named_maps[i].map_name for i in map_indices]\n",
    "        else:\n",
    "            map_names = []\n",
    "        return map_names\n",
    "\n",
    "    def label_tables(self, map_indices=None):\n",
    "        \"\"\"\n",
    "        get label tables\n",
    "        Parameters:\n",
    "        ----------\n",
    "        map_indices: sequence of integer\n",
    "            Specify which label tables should be got.\n",
    "            If None, get all label tables.\n",
    "        Return:\n",
    "        ------\n",
    "        label_tables: list of Cifti2LableTable\n",
    "        \"\"\"\n",
    "        named_maps = list(self.header.get_index_map(0).named_maps)\n",
    "        if named_maps:\n",
    "            if map_indices is None:\n",
    "                label_tables = [nm.label_table for nm in named_maps]\n",
    "            else:\n",
    "                label_tables = [named_maps[i].label_table for i in map_indices]\n",
    "        else:\n",
    "            label_tables = []\n",
    "        return label_tables\n",
    "\n",
    "    def get_stru_pos(self, structure):\n",
    "        \"\"\"\n",
    "        For a certain brain structure:\n",
    "        1. Get its position in the cifti data:\n",
    "            offset, count\n",
    "        2. Get its position in the intact map:\n",
    "            map_shape, index2v\n",
    "        Args:\n",
    "            structure (str): brain structure\n",
    "                Can be found by self.brain_structures\n",
    "        Returns:\n",
    "            offset (int): data offset\n",
    "                Offset of the brain structure in the cifti data.\n",
    "            count (int): the number of data points\n",
    "                Data point count of the brain structure in the cifti data.\n",
    "            map_shape (tuple): the shape of the map\n",
    "                If brain model type is SURFACE, the shape is (n_vertex,).\n",
    "                If brain model type is VOXELS, the shape is (i_max, j_max, k_max).\n",
    "            index2v (list): index to vertex or voxel\n",
    "                index2v[cifti_data_index] == vertex number or voxel position\n",
    "        \"\"\"\n",
    "        bm = self.brain_models([structure])[0]\n",
    "        offset, count = bm.index_offset, bm.index_count\n",
    "        if bm.model_type == 'CIFTI_MODEL_TYPE_SURFACE':\n",
    "            map_shape = (bm.surface_number_of_vertices,)\n",
    "            index2v = list(bm.vertex_indices)\n",
    "        elif bm.model_type == 'CIFTI_MODEL_TYPE_VOXELS':\n",
    "            # This function have not been verified visually.\n",
    "            map_shape = self.volume.volume_dimensions\n",
    "            index2v = list(bm.voxel_indices_ijk)\n",
    "        else:\n",
    "            raise RuntimeError(f'Not supported brain model: {bm.model_type}')\n",
    "\n",
    "        return offset, count, map_shape, index2v\n",
    "\n",
    "    def get_data(self, structure=None, zeroize=False):\n",
    "        \"\"\"\n",
    "        get data from cifti file\n",
    "        Parameters\n",
    "        ----------\n",
    "        structure: str\n",
    "            One structure corresponds to one brain model.\n",
    "            specify which brain structure's data should be extracted\n",
    "            If None, get all structures, meanwhile ignore parameter 'zeroize'.\n",
    "        zeroize: bool\n",
    "            If true, get data after filling zeros for the missing vertices/voxels.\n",
    "        Return\n",
    "        ------\n",
    "        data: numpy array\n",
    "            If zeroize is False, the data's shape is (n_map, n_index).\n",
    "            If zeroize is True and brain model type is SURFACE,\n",
    "                the data's shape is (n_map, n_vertex).\n",
    "            If zeroize is True and brain model type is VOXELS,\n",
    "                the data's shape is (n_map, i_max, j_max, k_max).\n",
    "        \"\"\"\n",
    "        _data = self.full_data.get_fdata()\n",
    "        if structure is not None:\n",
    "            bm = self.brain_models([structure])[0]\n",
    "            offset, count, map_shape, index2v = self.get_stru_pos(structure)\n",
    "            _data = _data[:, offset:offset+count]\n",
    "\n",
    "            if zeroize:\n",
    "                data_shape = (_data.shape[0],) + map_shape\n",
    "                data = np.zeros(data_shape, _data.dtype)\n",
    "                if bm.model_type == 'CIFTI_MODEL_TYPE_SURFACE':\n",
    "                    data[:, index2v] = _data\n",
    "                elif bm.model_type == 'CIFTI_MODEL_TYPE_VOXELS':\n",
    "                    index2v = np.array(index2v)\n",
    "                    data[:, index2v[:, 0], index2v[:, 1], index2v[:, 2]] = _data\n",
    "                else:\n",
    "                    raise RuntimeError(f'Not supported brain model: {bm.model_type}')\n",
    "            else:\n",
    "                data = _data\n",
    "        else:\n",
    "            data = _data\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cii = CiftiReader('template.dtseries.nii')\n",
    "_, _, _, index2v = cii.get_stru_pos('CIFTI_STRUCTURE_CORTEX_LEFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/code/nodanalysis/localizer-zscore-nii'\n",
    "sub='sub-01'\n",
    "spatialcode = 's4'\n",
    "for roi in ['vwfa-1', 'vwfa-2','owfa','body', 'ffa-1', 'ffa-2', 'ofa', 'place']:\n",
    "    nii =nib.load(pjoin(save_path,f'rg_{sub}_localizer_{roi}.nii')).get_fdata()\n",
    "    nii = np.squeeze(nii)\n",
    "    cii = nii[index2v]\n",
    "    roi_vertices = np.where(cii==1)\n",
    "    roi_mask = np.zeros(91282)\n",
    "    roi_mask[roi_vertices] = 1\n",
    "    save_ciftifile(roi_mask, pjoin(save_path, f'{sub}_{spatialcode}-{roi}.dtseries.nii'), 'template.dtseries.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw ROI\n",
    "sub = 'sub-01'\n",
    "spatialcode = '_s4'\n",
    "local_nii_path = '/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/code/nodanalysis/localizer-zscore-nii'\n",
    "if spatialcode:\n",
    "    nii_file = f'{sub}_localizer_zscore{spatialcode}.dtseries.nii'\n",
    "else:\n",
    "    nii_file = f'{sub}_localizer_zscore.dtseries.nii'\n",
    "# surf_gii_path = '/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/bold/derivatives/ciftify/sub-01/MNINonLinear/fsaverage_LR32k/'\n",
    "# gii_file = 'sub-01.L.very_inflated.32k_fs_LR.surf.gii'\n",
    "\n",
    "# gii = nib.load(pjoin(surf_gii_path, gii_file))\n",
    "# triangles = gii.agg_data('triangle')\n",
    "\n",
    "nii = nib.load(pjoin(local_nii_path, nii_file))\n",
    "data = nii.get_fdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-np.isnan(data)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2.33\n",
    "char_mask = data[0,:] > threshold\n",
    "char_vertices = np.where(char_mask==1)[0]\n",
    "body_vertices = np.where((data[1,:] > threshold) == 1)[0]\n",
    "face_vertices = np.where((data[2,:] > threshold) == 1)[0]\n",
    "place_vertices = np.where((data[3,:] > threshold) == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##>> handle the overlap boundary\n",
    "overlap_on_face = set(face_vertices) & (set(char_vertices) | set(body_vertices) | set(place_vertices))\n",
    "char_vertices = set(char_vertices) - overlap_on_face\n",
    "body_vertices = set(body_vertices) - overlap_on_face\n",
    "place_vertices = set(place_vertices) - overlap_on_face\n",
    "\n",
    "overlap_on_body = set(body_vertices) & (set(char_vertices) | set(place_vertices))\n",
    "char_vertices = char_vertices - overlap_on_body\n",
    "place_vertices = place_vertices - overlap_on_body\n",
    "\n",
    "overlap_on_place = set(place_vertices) & set(char_vertices)\n",
    "char_vertices = char_vertices - overlap_on_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_map = np.nan*np.zeros(91282)\n",
    "roi_map[list(body_vertices)] = 8\n",
    "roi_map[list(face_vertices)] = 4\n",
    "roi_map[list(char_vertices)] = -1\n",
    "roi_map[list(place_vertices)] = -5\n",
    "save_path = '/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/code/nodanalysis/localizer-zscore-nii'\n",
    "if spatialcode:\n",
    "    save_ciftifile(roi_map, pjoin(save_path, f'{sub}_roi_thres2.33{spatialcode}.dtseries.nii'), 'template.dtseries.nii')\n",
    "else:\n",
    "    save_ciftifile(roi_map, pjoin(save_path, f'{sub}_roi_thres2.33.dtseries.nii'), 'template.dtseries.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_vertices = char_vertices\n",
    "# mesh_indices = []\n",
    "# for i in range(triangles.shape[0]):\n",
    "#     cur_ver = triangles[i, :]\n",
    "#     if np.all([_ in roi_vertices for _ in cur_ver]):\n",
    "#         mesh_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[425, 683, 941, 1199]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[425+_*258 for _ in [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 2 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 1, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,4,5,6,8,9,10,11]\n",
    "print(np.diff(a))\n",
    "np.r_[1,np.diff(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nod_utils import save_ciftifile\n",
    "ver1 = np.unique([ _ for _ in triangles if 7322 in _])\n",
    "ver2 = np.unique([ _ for _ in triangles if 9031 in _])\n",
    "bmap = np.nan*np.zeros(91282)\n",
    "bmap[ver1] = 100\n",
    "bmap[ver2] = 10\n",
    "save_path = '/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/code/nodanalysis/inter-subject-animacymap'\n",
    "save_ciftifile(bmap, pjoin(save_path, f'verticeIndex.dtseries.nii'), 'template.dtseries.nii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7276, 7277, 7321, 7322, 7323, 7366, 7367], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = ny.freesurfer_subject('fsaverage')\n",
    "# /nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/bold/derivatives/freesurfer/sub-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/code/nodanalysis/prfresults.mat','r')\n",
    "file.keys()\n",
    "ciftifsaverageix = file['ciftifsaverageix'][:]\n",
    "ciftifsaveragebad = file['ciftifsaveragebad'][:]\n",
    "ix = np.squeeze(ciftifsaverageix.astype(np.int64)) - 1\n",
    "bad_id = np.squeeze(ciftifsaveragebad.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 327684)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "funcloc_path = '/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/code/nodanalysis/localizer-zscore-nii'\n",
    "subj = 'sub-04'\n",
    "\n",
    "pvalue = nib.load(pjoin(funcloc_path, f'{subj}_localizer_single-pvalue.dtseries.nii')).get_fdata()\n",
    "logpvalue = nib.load(pjoin(funcloc_path, f'{subj}_localizer_single-logpvalue.dtseries.nii')).get_fdata()\n",
    "\n",
    "pvalue = pvalue[:,ix]\n",
    "pvalue[:, bad_id] = np.nan\n",
    "logpvalue = logpvalue[:, ix]\n",
    "logpvalue[:, bad_id] = np.nan\n",
    "\n",
    "# get curvature\n",
    "curv_path = f'/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/bold/derivatives/ciftify/{subj}/MNINonLinear/fsaverage_LR32k'\n",
    "curv_file = f'{subj}.curvature.32k_fs_LR.dscalar.nii'\n",
    "curvature = np.squeeze(nib.load(pjoin(curv_path, curv_file)).get_fdata())\n",
    "fsa_curvature = curvature[ix]\n",
    "fsa_curvature[bad_id] = np.nan\n",
    "\n",
    "print(pvalue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f65af9dd5d48aa90e1996bbce7fd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=0.644570721372708, position=(0.0, 100.0, 0.0), projectionMa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot only on the cortical surface (i.e., exclude the Corpus callosum).\n",
    "# The 'cortex_label' property stores True values for cortex and False\n",
    "# values for the medial wall.\n",
    "import pythreejs\n",
    "import ipywidgets as widgets\n",
    "lh_valuemap = -logpvalue[:,0:163842]\n",
    "fig = ipv.figure()\n",
    "ny.cortex_plot(sub.lh, surface='inflated', color=lh_valuemap[0,:],figure=fig,\n",
    "               cmap='YlOrRd', vmin=2, vmax=12, underlay=-fsa_curvature[0:163842], mask=(lh_valuemap[0,0:163842]>=2), \n",
    "               view='front') #\n",
    "\n",
    "# ipv.pylab.style.box_on()\n",
    "# ipv.pylab.style.axes_on()\n",
    "# # ipv.pylab.quiver(0,0,0,1,0,0, color='red')\n",
    "# # ipv.pylab.quiver(0,0,0,0,1,0, color='blue')\n",
    "# # ipv.pylab.quiver(0,0,0,0,0,1, color='green')\n",
    "# ipv.pylab.xyzlabel('x','y','z')\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c9dadfdb7f436b9d91c97c50f4579d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(camera=PerspectiveCamera(fov=0.644570721372708, position=(0.0, 100.0, 0.0), projectionMatrix=(1.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rh_valuemap = -logpvalue[:,163842::]\n",
    "fig_rh = ipv.figure()\n",
    "ny.cortex_plot(sub.rh, surface='inflated', color=rh_valuemap[0,:],figure=fig_rh,\n",
    "               cmap='YlOrRd', vmin=1, vmax=12, underlay=-fsa_curvature[163842::], mask=(rh_valuemap[0,163842::]>=1), \n",
    "               view='front') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d1f81d8b0e4b38a0a435d3f8555cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(camera=PerspectiveCamera(fov=0.644570721372708, position=(0.0, -100.0, 0.0), projectionMatrix=(1.0, 0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ny.cortex_plot(sub.lh, surface='inflated', color='thickness',\n",
    "               cmap='hot', vmin=2, vmax=6,\n",
    "               mask=('thickness', 0, np.inf),\n",
    "               underlay='curvature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function figure in module ipyvolume.pylab:\n",
      "\n",
      "figure(key=None, width=400, height=500, lighting=True, controls=True, controls_vr=False, controls_light=False, debug=False, **kwargs)\n",
      "    Create a new figure (if no key is given) or return the figure associated with key\n",
      "    \n",
      "    :param key: Python object that identifies this figure\n",
      "    :param int width: pixel width of WebGL canvas\n",
      "    :param int height:  .. height ..\n",
      "    :param bool lighting: use lighting or not\n",
      "    :param bool controls: show controls or not\n",
      "    :param bool controls_vr: show controls for VR or not\n",
      "    :param bool debug: show debug buttons or not\n",
      "    :return: :any:`Figure`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ipv.figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###>> save to localizer-zscore-nii\n",
    "from nod_utils import save_ciftifile\n",
    "from scipy.stats import norm\n",
    "save_path = '/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/code/nodanalysis/localizer-zscore-nii'\n",
    "subject = 'sub-08'\n",
    "spatial_smoooth_code = '_s4'\n",
    "zscore = np.load(f'/nfs/z1/userhome/GongZhengXin/NVP/NaturalObject/data/bold/derivatives/beta/{subject}/{subject}_localizer-z_score{spatial_smoooth_code}.npy')\n",
    "save_ciftifile(zscore, pjoin(save_path, f'{subject}_localizer_zscore{spatial_smoooth_code}.dtseries.nii'), 'template.dtseries.nii')\n",
    "\n",
    "# log_zscore = norm.logsf(zscore)/np.log(10)\n",
    "# log_zscore[log_zscore>(np.log(0.1)/np.log(10))] = np.nan\n",
    "# save_ciftifile(log_zscore, pjoin(save_path, f'{subject}_localizer_single-logpvalue.dtseries.nii'), 'template.dtseries.nii')\n",
    "# p_zscore = norm.sf(zscore)\n",
    "# p_zscore[p_zscore>0.1] = np.nan\n",
    "# save_ciftifile(p_zscore, pjoin(save_path, f'{subject}_localizer_single-pvalue.dtseries.nii'), 'template.dtseries.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 91282)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_zscore[log_zscore>(np.log(0.1)/np.log(10))] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.461752333089393"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.089074968767317"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.min(norm.sf(zscore[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ded51e6ae5fb79fea0b0420ae45d65595baa7e9f6ec8445524f1c7cb23aaaa4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
