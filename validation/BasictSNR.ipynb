{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This file contains quality check on the original dtseries, currently it only contains the temporal signal-to-noise ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import time, os, pickle, json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from nod_utils import save_ciftifile\n",
    "from os.path import join as pjoin\n",
    "from matplotlib import font_manager\n",
    "font_manager.fontManager.addfont('./supportfiles/arial.ttf')\n",
    "# define plot utils\n",
    "mpl.rcParams['axes.linewidth'] = 2\n",
    "mpl.rcParams.update({'font.size': 12, 'font.family': 'Arial', 'mathtext.fontset': 'stix'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define calc tSNR function   \n",
    "def tsnr(data):\n",
    "    mean = data.mean(axis=-1)\n",
    "    std = data.std(axis=-1)\n",
    "    return np.nan_to_num(mean/std)\n",
    "\n",
    "# define the time-series function\n",
    "def get_task_time_series(sub_name, ciftify_dir, result_dir, task, n_run=None, roi_mat = None):\n",
    "    # MNINolinear/Results disposit all the runs data\n",
    "    _result_path = pjoin(ciftify_dir, sub_name, result_dir)\n",
    "    # extract the task runs\n",
    "    task_runs = [_ for _ in os.listdir(_result_path) if (task in _)]\n",
    "    task_runs.sort() \n",
    "    # initialize the mapping dict\n",
    "    stim_resp_map = {}\n",
    "    # loop run\n",
    "    if n_run :\n",
    "        task_runs = task_runs[:n_run]\n",
    "    for single_run in task_runs:\n",
    "        print(single_run + ' in ' + sub_name)\n",
    "        # prepare .feat/GrayordinatesStats dir\n",
    "        nii_dir = '{0}'.format(single_run)\n",
    "        nii_path = pjoin(ciftify_dir, sub_name, result_dir, nii_dir)\n",
    "        # loop trial \n",
    "        nii_file = pjoin(nii_path, '{0}_Atlas_hp128_s4.dtseries.nii'.format(single_run))\n",
    "        dt_data = nib.load(nii_file).get_fdata()\n",
    "        if roi_mat:\n",
    "            # only save roi\n",
    "            stim_resp_map[single_run] = np.array(dt_data[:, roi_mat])\n",
    "        else:\n",
    "            stim_resp_map[single_run] = np.array(dt_data)\n",
    "    # transfer to matrix\n",
    "    task_data = np.dstack(tuple([stim_resp_map[_] for _ in list(stim_resp_map.keys())]))\n",
    "    task_data = task_data.transpose((2,1,0)).astype(np.float32)\n",
    "    return task_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imagenet tsnr computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_path = '/nfs/z1/userhome/GongZhengXin/NVP/data_upload/NOD'\n",
    "ciftify_dir = f'{dataset_path}/derivatives/ciftify'\n",
    "result_dir = 'results/'\n",
    "beta_path = './supportfiles/'\n",
    "\n",
    "task_name = 'imagenet'\n",
    "\n",
    "n_run = None\n",
    "sub_names = ['sub-{:02d}'.format(i) for i in range(1,31)]\n",
    "# Violin plot of the tsnr distribution\n",
    "all_sub_tsnr_mean = np.zeros((len(sub_names),), dtype=object)\n",
    "\n",
    "for i, sub_name in enumerate(sub_names):\n",
    "    # handle special subject\n",
    "    tsnr_sub_path = pjoin(beta_path, sub_name, f'{sub_name}_imagenet-tsnr.npy')\n",
    "    if not os.path.exists(pjoin(beta_path, sub_name)):\n",
    "        os.makedirs(pjoin(beta_path, sub_name))\n",
    "    if not os.path.exists(tsnr_sub_path):\n",
    "        dtseries_sum = get_task_time_series(sub_name, ciftify_dir, result_dir, task_name)\n",
    "        tsnr_sum = np.zeros_like(dtseries_sum[:,:,0])\n",
    "        n_run = dtseries_sum.shape[0]   \n",
    "        for run in range(n_run):\n",
    "            run_data = dtseries_sum[run,:,:]\n",
    "            tsnr_sum[run, :] = tsnr(run_data)\n",
    "        tsnr_sub = tsnr_sum.mean(axis=1)\n",
    "        np.save(tsnr_sub_path, tsnr_sub)\n",
    "    else:\n",
    "        tsnr_sub = np.load(tsnr_sub_path)\n",
    "    # save in data\n",
    "    all_sub_tsnr_mean[i] = tsnr_sub\n",
    "np.save(pjoin(beta_path, f'sub-{task_name}_tsnr_mean.npy'), all_sub_tsnr_mean)\n",
    "\n",
    "# # save tsnr map\n",
    "# result_path = './supportfiles'\n",
    "\n",
    "# sub_names = sorted([i for i in os.listdir(beta_path) if i.startswith('sub-')]) \n",
    "# tsnr_merge = np.zeros((30, 91282))\n",
    "# for idx,sub_name in enumerate(sub_names):\n",
    "#     tsnr_merge[idx] = np.load(pjoin(beta_path, sub_name, f'{sub_name}_imagenet-tsnr.npy'))\n",
    "# tsnr_map = tsnr_merge.mean(axis=0)\n",
    "# save_ciftifile(tsnr_map, pjoin(result_path, 'tsnr_map_imagenet.dtseries.nii'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COCO tsnr computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_path = '/nfs/z1/userhome/GongZhengXin/NVP/data_upload/NOD'\n",
    "ciftify_dir = f'{dataset_path}/derivatives/ciftify'\n",
    "result_dir = 'results/'\n",
    "beta_path = './supportfiles/'\n",
    "\n",
    "task_name = 'coco'\n",
    "\n",
    "sub_names = sorted(['sub-{:02d}'.format(i) for i in range(1,10)]) \n",
    "\n",
    "all_sub_tsnr_mean = np.zeros((len(sub_names),), dtype=object)\n",
    "\n",
    "for i, sub_name in enumerate(sub_names):\n",
    "    # handle special subject\n",
    "    tsnr_sub_path = pjoin(beta_path, sub_name, f'{sub_name}_coco-tsnr.npy')\n",
    "    if not os.path.exists(tsnr_sub_path):\n",
    "        dtseries_sum = get_task_time_series(sub_name, ciftify_dir, result_dir, task_name)\n",
    "        tsnr_sum = np.zeros_like(dtseries_sum[:,:,0])\n",
    "        n_run = dtseries_sum.shape[0]   \n",
    "        for run in range(n_run):\n",
    "            run_data = dtseries_sum[run,:,:]\n",
    "            tsnr_sum[run, :] = tsnr(run_data)\n",
    "        tsnr_sub = tsnr_sum.mean(axis=1)\n",
    "        np.save(tsnr_sub_path, tsnr_sub)\n",
    "    else:\n",
    "        tsnr_sub = np.load(tsnr_sub_path)\n",
    "    # concatenate data\n",
    "    all_sub_tsnr_mean[i] = tsnr_sub\n",
    "\n",
    "np.save(pjoin(beta_path, f'sub-{task_name}_tsnr_mean.npy'), all_sub_tsnr_mean)\n",
    "\n",
    "# # save tsnr map\n",
    "# result_path = './supportfiles'\n",
    "\n",
    "# tsnr_merge = np.zeros((len(sub_names), 91282))\n",
    "# for idx,sub_name in enumerate(sub_names):\n",
    "#     tsnr_merge[idx] = np.load(pjoin(beta_path, sub_name, f'{sub_name}_coco-tsnr.npy'))\n",
    "# tsnr_map = tsnr_merge.mean(axis=0)\n",
    "# save_ciftifile(tsnr_map, pjoin(result_path, 'tsnr_map_coco.dtseries.nii'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For localizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_path = '/nfs/z1/userhome/GongZhengXin/NVP/data_upload/NOD'\n",
    "ciftify_dir = f'{dataset_path}/derivatives/ciftify'\n",
    "result_dir = 'results/'\n",
    "beta_path = './supportfiles/'\n",
    "\n",
    "task_name = 'floc'\n",
    "\n",
    "sub_names = sorted(['sub-{:02d}'.format(i) for i in range(1,10)]) \n",
    "\n",
    "all_sub_tsnr_mean = np.zeros((len(sub_names),), dtype=object)\n",
    "\n",
    "for i, sub_name in enumerate(sub_names):\n",
    "    # handle special subject\n",
    "    tsnr_sub_path = pjoin(beta_path, sub_name, f'{sub_name}_localizer-tsnr.npy')\n",
    "    if not os.path.exists(tsnr_sub_path):\n",
    "        dtseries_sum = get_task_time_series(sub_name, ciftify_dir, result_dir, task_name)\n",
    "        tsnr_sum = np.zeros_like(dtseries_sum[:,:,0])\n",
    "        n_run = dtseries_sum.shape[0]   \n",
    "        for run in range(n_run):\n",
    "            run_data = dtseries_sum[run,:,:]\n",
    "            tsnr_sum[run, :] = tsnr(run_data)\n",
    "        tsnr_sub = tsnr_sum.mean(axis=1)\n",
    "        np.save(tsnr_sub_path, tsnr_sub)\n",
    "    else:\n",
    "        tsnr_sub = np.load(tsnr_sub_path)\n",
    "    # collect data\n",
    "    all_sub_tsnr_mean[i] = tsnr_sub\n",
    "np.save(pjoin(beta_path, f'sub-{task_name}_tsnr_mean.npy'), all_sub_tsnr_mean)\n",
    "\n",
    "# # save tsnr map\n",
    "# result_path = './supportfiles'\n",
    "# tsnr_merge = np.zeros((len(sub_names), 91282))\n",
    "# for idx,sub_name in enumerate(sub_names):\n",
    "#     tsnr_merge[idx] = np.load(pjoin(beta_path, sub_name, f'{sub_name}_localizer-tsnr.npy'))\n",
    "# tsnr_map = tsnr_merge.mean(axis=0)\n",
    "# save_ciftifile(tsnr_map, pjoin(result_path, 'tsnr_map_localizer.dtseries.nii'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For retinotopy data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_path = '/nfs/z1/userhome/GongZhengXin/NVP/data_upload/NOD'\n",
    "ciftify_dir = f'{dataset_path}/derivatives/ciftify'\n",
    "result_dir = 'results/'\n",
    "beta_path = './supportfiles/'\n",
    "\n",
    "task_name = 'prf'\n",
    "\n",
    "sub_names = sorted(['sub-{:02d}'.format(i) for i in range(1,10)]) \n",
    "\n",
    "all_sub_tsnr_mean = np.zeros((len(sub_names),), dtype=object)\n",
    "\n",
    "for i, sub_name in enumerate(sub_names):\n",
    "    # handle special subject\n",
    "    tsnr_sub_path = pjoin(beta_path, sub_name, f'{sub_name}_retinotopy-tsnr.npy')\n",
    "    if not os.path.exists(tsnr_sub_path):\n",
    "        dtseries_sum = get_task_time_series(sub_name, ciftify_dir, result_dir, task_name)\n",
    "        tsnr_sum = np.zeros_like(dtseries_sum[:,:,0])\n",
    "        n_run = dtseries_sum.shape[0]   \n",
    "        for run in range(n_run):\n",
    "            run_data = dtseries_sum[run,:,:]\n",
    "            tsnr_sum[run, :] = tsnr(run_data)\n",
    "        tsnr_sub = tsnr_sum.mean(axis=1)\n",
    "        np.save(tsnr_sub_path, tsnr_sub)\n",
    "    else:\n",
    "        tsnr_sub = np.load(tsnr_sub_path)\n",
    "    # collect data\n",
    "    all_sub_tsnr_mean[i] = tsnr_sub\n",
    "# save\n",
    "np.save(pjoin(beta_path, f'sub-{task_name}_tsnr_mean.npy'), all_sub_tsnr_mean)\n",
    "\n",
    "# # save tsnr map\n",
    "# result_path = './supportfiles'\n",
    "# tsnr_merge = np.zeros((len(sub_names), 91282))\n",
    "# for idx,sub_name in enumerate(sub_names):\n",
    "#     tsnr_merge[idx] = np.load(pjoin(beta_path, sub_name, f'{sub_name}_retinotopy-tsnr.npy'))\n",
    "# tsnr_map = tsnr_merge.mean(axis=0)\n",
    "# save_ciftifile(tsnr_map, pjoin(result_path, 'tsnr_map_retinotopy.dtseries.nii'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ded51e6ae5fb79fea0b0420ae45d65595baa7e9f6ec8445524f1c7cb23aaaa4c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
